# Cache替换策略

萌萌酱

[TOC]

## 实验概述

本次实验实现了 C/C++编写的 Cache 替换策略模拟器。输入为存储器访问 trace， 输出为在不同的条件下(如 Cache 块大小，组织方式替换策略，不同的写策略等)，在给定 trace 上的缺失率，以及访问 log(记录命中和缺失的结果)。

1. 可修改参数的 cache 替换策略模拟器，包括cache大小(cache_size)、缓存大小(cache_size)、块大小(block_size)、相联度(way)、替换算法(replace_policy)、写策略(write_alloc、write_through)、输入文件、输出文件。
2. 相关参数可以在.sh文件中给出。在目录下使用`make`命令编译后，可以仿照`test.sh`格式编写`.sh`文件制定参数并得到运行输出。
3. 以多态的形式实现替换算法，每个算法实现为独立的文件。
4. 实现了 LRU、PLRU、RANDOM 替换算法，并通过输入参数计算所需空间、根据位运算维护替换算法数据，将所需空间降到最小。LRU算法用uint_8数组保存，对于每个块需要的数据长度为 $\log_2(way)$ ，则数组长度为 $way * \log_2(way) / 8$ 。PLRU 使用按位的二叉树实现，也由 uint_8 数组保存，数组长度为 $way / 8$ 。
5. cache的元数据使用uint64_t维护，原因在下面给出 

## 代码实现

### 实验思路

总体思路是Cache的**数据和替换策略分离**。因为Cache希望能实现多种替换策略，而且替换策略和具体数据无关，只和这一组之内访问了哪一个块有关。因此替换策略适合使用多态实现，只处理和访问信息有关的数据。

### 代码框架

#### Cache的成员变量：

```c++
uint32_t cache_size_;//单位kb
uint32_t block_size_;//单位b
uint32_t block_offset_;//表示block offset有几位
uint32_t way_;//表示映射方式，way=1:直接映射，输入way=0表示全相联，会在构造函数中计算
uint32_t group_;//一共有多少组
uint32_t group_bit_;//用来表示组的index有多少位
uint32_t flag_;//标签位有多少位
POLICY replace_policy_;//替换策略
bool is_Write_Alloc_;//是否写分配
bool is_Write_Through_;//是否写通过

replacement_policy* replacementPolicy;//用于实现替换策略
uint64_t* data_;//用于存储数据
```

在Cache中的成员变量较多，实际上并不需要这么多的信息就完全可以描述一个cache。不过这样是为了编码方便，而且Cache在全局只会有一个实例，相比Cache当中data，它们的大小可以忽略不计。

为了编码方便还是使用了64位无符号int来存储cache当中的数据。可能会产生一定的浪费，而且如果需要存储的长度超过64位就会在存储上出现错误。对于存储出现错误的问题，采用的方式是在构造函数当中使用`assert(flag_ + 2<=ADDR_LEN);`语句判断flag的长度是否合法。但是实际上也并不需要担心，因为flag是通过如下语句计算出的，而用来表示组的位数和用来表示block的位数一定都是>=1的。

```c++
flag_ = ADDR_LEN - group_bit_ - block_offset_;//标签位=地址长度-组数-块内位移
```

关于产生的空间浪费问题，在最坏情况下是直接映射时，flag有47位，再加上dirty位和valid位是49位，空间利用率达到76%，相对来说影响较小，因此没有实现用char数组存储。

#### Cache的私有成员函数

```c++
private:
		//此函数封装了位运算，含义是取出64位的addr中，从右往左数第right位开始截取length位
    uint64_t get_some_bits(uint64_t addr, uint64_t right,uint64_t length);

    //处理器给cache一个地址后，取出它在哪个组
    uint64_t get_group(uint64_t addr);

    //处理器给cache一个地址后，取出它的标签位
    uint64_t get_flag(uint64_t addr);

    //cache中存储的数据中取出标签位
    uint64_t get_flag_from_data(uint64_t data);
    //cache中存储的数据判断这是否为可用数据
    bool is_valid_data(uint64_t data);
    //判断数据是否为dirty（在写回策略时使用，用于告诉主存这里有个数据要flush进来
    bool is_dirty_data(uint64_t data);

    //取出块内位移，不过在本次实验当中似乎没有用到
    uint64_t get_block_offset(uint64_t addr);

    //想把addr存储到cache里面时应该存进去什么
    uint64_t store_data(uint64_t addr);

    //用于输出addr的二进制
    void outputbin(uint64_t addr);
```

#### Cache的公有成员函数

cache对外提供的接口如下

```c++
public:
    Cache(uint32_t cache_size, uint32_t block_size,
            uint32_t way, POLICY replace_policy,
            bool is_write_alloc):
            cache_size_(cache_size),block_size_(block_size),
            way_(way),replace_policy_(replace_policy),
            is_Write_Alloc_(is_write_alloc){
        assert(way_==0||way_==1||way_==2||way_==4||way_==8);
        if(way_ == 0)way_=(cache_size_<<10)/(block_size_);//way = 0表示全相联，这里计算一下它到底是多少路
        group_ = (cache_size_<<10)/(block_size_*way_);//组数=cache容量/(块大小*每组当中的块数)
        group_bit_ = uint32_t(ceil(log(group_)/log(2)));//组数需要多少位来表示
        block_offset_ = uint32_t(ceil(log(block_size_)/log(2)));//计算块内位移所占的大小
        flag_ = ADDR_LEN - group_bit_ - block_offset_;//标签位=地址长度-组数-块内位移
        assert(flag_ + 2<=64);
        init_policy();
        init_alloc();
    }
    bool data_read(uint64_t addr);//读数据
    bool data_write(uint64_t addr);//写数据
```



### 三种替换策略

在实现cache时实现了3种替换策略：LRU，PLRU和RANDOM。它们有一个共同的基类是replacement_policy，有共同的接口：

```c++
virtual uint32_t get_victim(uint32_t group) = 0;//返回按照当前的访问状态，被替换的victim会是谁
virtual void visited(uint32_t group,uint32_t node) = 0;//表示对第group组的第node个节点进行了访问
```

对于cache的每一个组都要维护一个栈/二叉树/策略节点，用来记录一个组内的访问状态，每一个替换策略使用策略节点数组来维护。因此对于每一个策略节点也实现一个共同的基类，有共同的接口：

```c++
virtual uint32_t get_victim() = 0;
virtual void visit(uint32_t v) = 0;
```

这种实现方式有两个主要的好处：

- 非常方便扩展新的替换策略
- 将数据和实现分离。

不过需要注意的是：

函数get_victim()只负责返回哪个节点被替换，并不会在函数里面对策略节点的状态进行更新。因此如果真的要替换某个节点，在cache当中实现时分为三步：

1. 获得组内被替换的节点
2. 修改数据
3. 更新替换策略的状态信息（调用visit）

以下具体描述三种替换策略的实现。其中，LRU和PLRU都实现了在uint8_t数组中按位存储访问信息，而随机替换算法并不需要存储访问信息。



---

#### LRU

LRU 算法中，每次替换会在组内找到最长时间未访问的块进行替换。该算法充分利用了程序访问的局部性。如果程序访问的空间范围较小，这个算法的命中率将会较好。但是大小大于 cache 容量的数组，在采用行优先存储并按列访问时，缺失率将达到 100% 。

在实现LRU时首先实现lru的策略节点。该节点实现两个接口：

```c++
uint32_t get_victim() override{
    return get(tway_-1);
}
void visit(uint32_t v) override{
    uint32_t v_=0;
    for(uint32_t i=0;i<tway_;i++){
        if(get(i)==v){
            v_=i;
            break;
        }
    }
    for(uint32_t j=v_;j>0;j--){
        put(j,get(j-1));
    }
    put(0,v);
}
```

对于lru来说，策略节点是一个存储了组内访问顺序的数组。它维护了一个栈，每当一块被访问，就将其从栈里取出这一块并将它压入栈顶，选择被替换的块时选择栈底的块。使用了按位的实现。由于无法实现知道多少路以及它占用几个bit，只能在初始化时申请空间。而且不能把长度信息存储在policy-node当中，否则占用的空间可能会比一个node本身需要的空间还大。因此这里使用两个静态变量存储way的信息，在policy_lru初始化时为静态变量赋值，并在lru策略初始化时调用策略节点的构造函数来申请空间。相关代码如下：

静态变量：

```c++
static uint32_t tway_;//共有多少路
static uint32_t tlogway_;//log之后向上取整有几位
```

in lru_stack

```c++
lru_stack()
{
    uint32_t len = (tway_ * tlogway_ +7)/8;
    stack = new uint8_t[len];
    for(int i=0;i<tway_;i++){
        put(i,i);
    }
}
```

注意在lru初始化时需要赋给stack初值，默认每一个位置上的初值=自己的下标。

in policy_lru

```c++
void init_policy(){
        tway_ = way_; tlogway_ = uint32_t(ceil(log(way_)/log(2)));
#ifdef DEBUG
        cout<<"tway_ = "<<tway_<<" tlogway_ = "<<tlogway_<<endl;
#endif
        s = new lru_stack[group_];
    }

public:
    policy_lru(uint32_t cache_size, uint32_t group,
               uint32_t way, POLICY policy)
               :replacement_policy
               (cache_size, group,way, policy){
        init_policy();
    }

    ~policy_lru() override{
        delete []s;
    }
```



---

#### PLRU

PLRU 算法中，使用按位二叉树对访问信息进行维护。对于PLRU的策略节点的接口实现如下：

```c++
    uint32_t get_victim() override {
        uint32_t pos = 0, cal = 0;
        for(uint32_t i = 0; i< tlogway_plru;i ++){
            bool b = get_bit(pos);
            if(b){
                cal += (1 << (tlogway_plru - 1 - i));
                pos = (pos<<1) + 2;
            } else{
                pos = (pos<<1) + 1;
            }
        }
        return cal;
    }

    void visit(uint32_t t) override {
        assert(t<tway_plru&&t>=0);
        uint32_t pos=0;
        for(uint32_t i = 0;i<tlogway_plru;i++){
            bool b = (t >> (tlogway_plru -1 - i))&uint8_t(1);
            if(b){
                put_bit(pos, false);
                pos = (pos << 1) + 2;
            } else{
                put_bit(pos, true);
                pos = (pos << 1) + 1;
            }
        }
    }
```

对于plru来说，策略节点是一个按位的二叉树。和lru策略节点一样，它使用了按位的实现。由于无法实现知道多少路以及它占用几个bit，只能在初始化时申请空间。而且不能把长度信息存储在policy-node当中，否则占用的空间可能会比一个node本身需要的空间还大。因此这里使用两个静态变量存储way的信息，在policy_lru初始化时为静态变量赋值，并在lru策略初始化时调用策略节点的构造函数来申请空间。相关代码如下：

静态变量：

```c++
static uint32_t tway_plru;//共有多少路
static uint32_t tlogway_plru;//log之后向上取整有几位
```

in plru_tree

```c++
    plru_tree(){
        uint32_t len = (tway_plru - 1 + 7)/8;
        bin = new uint8_t[len];
    }
```

in policy_plru

```c++
class policy_plru: public replacement_policy{
    plru_tree* t;
    void init_policy(){
        tway_plru = way_;
        tlogway_plru = uint32_t(ceil(log(way_)/log(2)));
        t = new plru_tree[group_];
    }

public:
    policy_plru(uint32_t cache_size,
                uint32_t group,uint32_t way, POLICY policy):
                replacement_policy(cache_size, group,way, policy){
        init_policy();
    }

    ~policy_plru() override{
        delete []t;
    }

    uint32_t get_victim(uint32_t group) override {
        return t[group].get_victim();
    }

    void visited(uint32_t group,uint32_t node) override{
        t[group].visit(node);
    }
};
```



---

#### RANDOM 

随机替换算法的实现最为简单，不需要额外的空间去实现策略节点也不需要记录访问状态信息，只需要在每次需要替换时随机返回一个被替换的块即可：

```c++
		uint32_t get_victim(uint32_t group) override{
        uint32_t r = rand()%way_;
        return r;
    }

    void visited(uint32_t group,uint32_t node) override{

    }
```

在random替换算法下，对于不同特征的trace访问均有较为平稳的表现，缺失率在不同trace情况下表现较为稳定，不会遇到某些替换策略在某种特定的访问顺序下可能出现的最坏情况。



## 实验结果分析

### 固定 Cache 布局,尝试不同的 Cache 替换策略

在固定 Cache 布局(块大小 8B，8-way 组关联)，固定写策略(写分配+写回)的前提下，尝试了不同的 Cache 替换策略：LRU，随机替换，二叉树替换算法。结果如下（由于excel出现一点问题，无法作图，所以结果只能以表格形式呈现）：

| filename        | blocksize | way  | policy   | iswritealloc | iswriteback | hit    | miss   | missrate  |
| --------------- | --------- | ---- | -------- | ------------ | ----------- | ------ | ------ | --------- |
| astar.trace     | 8         | 8    | P_LRU    | 1            | 1           | 384702 | 116766 | 0.232848  |
| astar.trace     | 8         | 8    | P_PLRU   | 1            | 1           | 384689 | 116779 | 0.232874  |
| astar.trace     | 8         | 8    | P_RANDOM | 1            | 1           | 384970 | 116498 | 0.232314  |
| bzip2.trace     | 8         | 8    | P_LRU    | 1            | 1           | 537887 | 6627   | 0.0121705 |
| bzip2.trace     | 8         | 8    | P_PLRU   | 1            | 1           | 537887 | 6627   | 0.0121705 |
| bzip2.trace     | 8         | 8    | P_RANDOM | 1            | 1           | 537887 | 6627   | 0.0121705 |
| mcf.trace       | 8         | 8    | P_LRU    | 1            | 1           | 484468 | 23232  | 0.0457593 |
| mcf.trace       | 8         | 8    | P_PLRU   | 1            | 1           | 484468 | 23232  | 0.0457593 |
| mcf.trace       | 8         | 8    | P_RANDOM | 1            | 1           | 484369 | 23331  | 0.0459543 |
| perlbench.trace | 8         | 8    | P_LRU    | 1            | 1           | 498357 | 9084   | 0.0179016 |
| perlbench.trace | 8         | 8    | P_PLRU   | 1            | 1           | 498392 | 9049   | 0.0178326 |
| perlbench.trace | 8         | 8    | P_RANDOM | 1            | 1           | 498358 | 9083   | 0.0178996 |

可以看出，在4个重点trace当中，在同一个trace中使用不同的替换策略得到的结果较为接近。说明cache的效果和数据的组织高度相关。



### 固定 Cache 布局，固定替换策略，尝试不同的写策略

固定 Cache 布局(块大小 8B，8-way 组关联)，固定替换策略(LRU)的前提下，尝试不同的写策略：

| filename    | blocksize | way  | policy | iswritealloc | iswritethrough | hit    | miss   | missrate  |
| ----------- | --------- | ---- | ------ | ------------ | -------------- | ------ | ------ | --------- |
| astar.trace | 8         | 8    | P_LRU  | 0            | 1              | 328467 | 173001 | 0.344989  |
| astar.trace | 8         | 8    | P_LRU  | 0            | 0              | 328467 | 173001 | 0.344989  |
| astar.trace | 8         | 8    | P_LRU  | 1            | 1              | 384702 | 116766 | 0.232848  |
| astar.trace | 8         | 8    | P_LRU  | 1            | 0              | 384702 | 116766 | 0.232848  |
| bzip2.trace | 8         | 8    | P_LRU  | 0            | 1              | 497305 | 47209  | 0.0866993 |
| bzip2.trace | 8         | 8    | P_LRU  | 0            | 0              | 497305 | 47209  | 0.0866993 |
| bzip2.trace | 8         | 8    | P_LRU  | 1            | 1              | 537887 | 6627   | 0.0121705 |
| bzip2.trace | 8         | 8    | P_LRU  | 1            | 0              | 537887 | 6627   | 0.0121705 |
| mcf.trace   | 8         | 8    | P_LRU  | 0            | 1              | 451107 | 56593  | 0.111469  |
| mcf.trace   | 8         | 8    | P_LRU  | 0            | 0              | 451107 | 56593  | 0.111469  |
| mcf.trace   | 8         | 8    | P_LRU  | 1            | 1              | 484468 | 23232  | 0.0457593 |
| mcf.trace   | 8         | 8    | P_LRU  | 1            | 0              | 484468 | 23232  | 0.0457593 |

可以看出，不同的写策略下，是否写分配对缺失率影响较大，写通过/写回对缺失率无影响。这一点比较容易理解，这四个trace的写操作都有一定的比例，因此如果写操作局部性也较强，那么采用写分配策略对缺失率的降低较为明显。而是否写通过其实对于cache的读写和数据存储无关。写回策略是在cache中数据即将被替换出去时，如果一个数据是dirty的话，则修改**主存**，对于cache本身的数据读写没有影响。



## 实验总结

### 收获

本次实验代码量适中，难度也适中，但是收获非常大。

在**代码能力方面**得到了较大提升，体会较大的是位运算和面向对象的思想，以及要注意编写单测。

1. 有时候位运算可能并不能得到自己预想的结果，尤其是在cache.cpp文件当中用到了大量的位运算来实现，例如常量数字并不会自己变成我以为的uint64_t类型，需要进行强制类型转换，否则如果用一个常量数字1来直接和一个uint64_t类型的数据进行按位与，它会自动向长度较短的类型进行转换，也就是说uint64_t会丢失前32位。这也是为什么最开始我在取出flag时会丢失不少的数据。

2. 面向对象的思想要感谢刘丰源同学对我的帮助，在替换策略上利用多态可以使代码结构更加清晰，也能减少很多代码量。此外我了解了纯虚析构函数必须自己定义函数体，否则会出现链接错误。

3. 编写单测会非常有助于定位bug，会极大地减少工作量。例如lru和plru的替换策略我都在正式应用前编写了一些测试，简单检验了正确性，因此在加入到程序框架当中之后并没有在替换策略这方面发现问题。而cache我没有进行测试，因此在正式运行时几乎所有的bug都来自cache的位运算。

在**对cache的理解方面**也有了较大的提升。一方面是全相联之前了解很少，通过实验得到了进一步理解；另一方面是写直达和写回策略对cache实现的影响。

感谢老师和助教给了我这次锻炼的机会。

### 和同学之间的交流

感谢**xy-plusplus**在代码实现上对我的帮助，在代码实现框架和细节处理方面都帮助很大，包括但不限于：在lru和plru策略实现的头文件当中使用静态变量以节省空间，lru部分栈的实现方式等。尤其是在**cache的替换策略部分的面向对象思想**这一点上对我启发很大，代码结构因此变得较为清晰。

感谢**dylanyang17**在cache的相关知识方面对我的帮助，例如帮助我理解了cache的写直达和写回。